{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"MLCube","text":"<p>MLCube\u00ae is a project that reduces friction for machine learning by ensuring that models are easily portable and  reproducible, e.g., between different stacks such as different clouds, between cloud and on-prem, etc.</p> <p>Interested in getting started with MLCube? Follow the  Getting Started instructions, or watch the video below.</p> <p></p>"},{"location":"#installing-mlcube","title":"Installing MLCube","text":"<p>Create python environment</p> CondaVirtualEnv <pre><code>conda create -n mlcube python=3.8\nconda activate mlcube\n</code></pre> <pre><code>virtualenv --python=3.8 .mlcube\nsource .mlcube/bin/activate\n</code></pre> <p>Install MLCube with docker and singularity runners <pre><code>pip install mlcube mlcube-docker docker-singularity\n</code></pre></p>"},{"location":"#usage-examples","title":"Usage Examples","text":"<p>Check out the examples for detailed examples.</p>"},{"location":"#license","title":"License","text":"<p>MLCube is licensed under the Apache License 2.0. </p> <p>See LICENSE for more information.</p>"},{"location":"#support","title":"Support","text":"<p>Create a GitHub issue</p>"},{"location":"getting-started/","title":"Installation","text":"<p>Here is the step-by-step guide to install MLCube\u00ae library and run simple MLCube cubes.</p>"},{"location":"getting-started/#create-a-python-environment","title":"Create a python environment","text":"CondaVirtualEnv <pre><code>conda create -n mlcube python=3.8\nconda activate mlcube\n</code></pre> <pre><code>virtualenv --python=3.8 .mlcube\nsource .mlcube/bin/activate\n</code></pre>"},{"location":"getting-started/#install-mlcube-runners","title":"Install MLCube Runners","text":"<p>Reference MLCube runners are distributed in separate python packages.</p> DockerSingularityGCP (alpha)K8S (alpha)Kubeflow (alpha)SSH (alpha) <pre><code>pip install mlcube-docker    \n</code></pre> <pre><code>pip install mlcube-singularity    \n</code></pre> <pre><code>pip install mlcube-gcp    \n</code></pre> <pre><code>pip install mlcube-k8s    \n</code></pre> <pre><code>pip install mlcube-kubeflow    \n</code></pre> <pre><code>pip install mlcube-ssh    \n</code></pre> <p>Warning</p> <p>GCP (Google Cloud Platform),  K8S (Kubernetes),  Kubeflow and  SSH runners are in early stages of development.</p> <p>Check that the docker runner has been installed. <pre><code>mlcube config --get runners\n</code></pre></p> <p>Show MLCube system settings. <pre><code>mlcube config --list\n</code></pre></p> <p>Information</p> <p>This system settings file (<code>~/mlcube.yaml</code>) configures local MLCube runners. Documentation for MLCube runners  describes each of these parameters in details. A typical first step for enterprise environments that are usually  behind a firewall is to configure proxy servers. <pre><code>platforms:\n  docker:\n    env_args:\n      http_proxy: http://ADDRESS:PORT\n      https_proxy: https://ADDRESS:PORT\n    build_args:\n      http_proxy: http://ADDRESS:PORT\n      https_proxy: https://ADDRESS:PORT\n</code></pre></p>"},{"location":"getting-started/#explore-with-examples","title":"Explore with examples","text":"<p>A great way to learn about MLCube is try out the example MLCube cubes  located in the mlcube_examples GitHub repository. <pre><code>git clone https://github.com/mlcommons/mlcube_examples.git \ncd ./mlcube_examples\nmlcube describe --mlcube ./mnist\n</code></pre></p>"},{"location":"getting-started/cli/","title":"Command Line Interface","text":""},{"location":"getting-started/cli/#mlcube","title":"mlcube","text":"<p>MLCube\u00ae is a tool for packaging, distributing and running Machine Learning (ML) projects and models.</p> <ul> <li>GitHub: https://github.com/mlcommons/mlcube</li> <li>Documentation: https://mlcommons.github.io/mlcube/</li> <li>Example MLCubes: https://github.com/mlcommons/mlcube_examples</li> </ul> <p>Usage:</p> <pre><code>mlcube [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--log-level</code>, <code>--log_level</code> choice (<code>critical</code> | <code>error</code> | <code>warning</code> | <code>info</code> | <code>debug</code>) Logging level is a lower-case string value for Python's logging library (see Logging Levels for more details). Only messages with this logging level or higher are logged. <code>warning</code> <code>--help</code>, <code>-h</code> boolean Show help message and exit. <code>False</code> <p>Subcommands</p> <ul> <li>config: Display or change MLCube system settings.</li> <li>configure: Configure MLCube.</li> <li>create: Create a new Python project from the MLCube cookiecutter template.</li> <li>describe: Describe this MLCube.</li> <li>inspect: Return low-level information on MLCube objects.</li> <li>run: Run MLCube task(s).</li> <li>show_config: Show effective MLCube configuration.</li> </ul>"},{"location":"getting-started/cli/#mlcube-config","title":"mlcube config","text":"<p>Display or change MLCube system settings.</p> <p>MLCube system settings define global configuration common for all MLCube runners and platforms. When this command runs without arguments, a path to system settings file is printed out. This is useful to automate certain operations with system settings. system settings file is printed out. This is useful to automate certain operations with system settings.</p> <p>Alternatively, it may be easier to manipulate system settings file directly (it is a yaml file).</p> <p>Usage:</p> <pre><code>mlcube config [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--list</code> boolean Print out the content of system settings file. <code>False</code> <code>--get</code> text Return value of the key (use OmegaConf notation, e.g. <code>mlcube config --get runners.docker</code>). None <code>--create_platform</code>, <code>--create-platform</code> tuple Create a new platform instance for this runner. Default runner parameters are used to initialize this new platform. None <code>--remove_platform</code>, <code>--remove-platform</code> text Remove this platform. If this is one of the default platforms (e.g., <code>docker</code>), it will be recreated (with default values) next time <code>mlcube</code> runs. None <code>--rename_platform</code>, <code>--rename-platform</code> tuple Rename existing platform. If default platform is to be renamed (e.g., <code>docker</code>), it will be recreated (with default values) next time <code>mlcube</code> runs. None <code>--copy_platform</code>, <code>--copy-platform</code> tuple Copy existing platform. This can be useful for creating new platforms off existing platforms, for instance,creating a new SSH runner configuration that runs MLCubes on a new remote server. None <code>--rename_runner</code>, <code>--rename-runner</code> tuple Rename existing MLCube runner. If platforms exist that reference this runner, users must explicitly provide <code>--update-platforms</code> flag to confirm they want to update platforms' description too. None <code>--remove_runner</code>, <code>--remove-runner</code> text Remove existing runner. If platforms exist that reference this runner, users must explicitly provide <code>--remove-platforms</code> flag to confirm they want to remove platforms too. None <code>--help</code>, <code>-h</code> boolean Show help message and exit. <code>False</code>"},{"location":"getting-started/cli/#mlcube-configure","title":"mlcube configure","text":"<p>Configure MLCube.</p> <p>Some MLCube projects need to be configured first. For instance, docker-based MLCubes distributed via GitHub with source code most likely will provide a <code>Dockerfile</code> to build a docker image. In this case, the process of building a docker image before MLCube runner can run it, is called a configuration phase. In general, users do not need to run this command manually - MLCube runners should be able to figure out when they need to run it, and will run it as part of <code>mlcube run</code> command.</p> <p>Usage:</p> <pre><code>mlcube configure [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--mlcube</code> text Path to an MLCube project. It can be a directory path, or a path to an MLCube configuration file. When it is a directory path, MLCube runtime assumes this directory is the MLCube root directory containing <code>mlcube.yaml</code> file. When it is a file path, this file is assumed to be the MLCube configuration file (<code>mlcube.yaml</code>), and a parent directory of this file is considered to be the MLCube root directory. Default value is current directory. None <code>--platform</code> text Platform name to run MLCube on (a platform is a configured instance of an MLCube runner). Multiple platforms are supported, including <code>docker</code> (Docker and Podman), <code>singularity</code> (Singularity). Other runners are in experimental stage: <code>gcp</code> (Google Cloud Platform), <code>k8s</code> (Kubernetes), <code>kubeflow</code> (KubeFlow), ssh (SSH runner). Default is <code>docker</code>. Platforms are defined and configured in MLCube system settings file. <code>docker</code> <code>-P</code>, <code>-p</code> text MLCube configuration parameter is a key-value pair. Must start with <code>-P</code> or '-p'. The dot (.) is used to refer to nested parameters, for instance, <code>-Pdocker.build_strategy=always</code>. These parameters have the highest priority and override any other parameters in system settings and MLCube configuration. None <code>--help</code>, <code>-h</code> boolean Show help message and exit. <code>False</code>"},{"location":"getting-started/cli/#mlcube-create","title":"mlcube create","text":"<p>Create a new Python project from the MLCube cookiecutter template.</p> <p>MLCube uses the cookiecutter library with the mlcube_cookiecutter template. The library is not installed automatically: install it with <code>pip install cookiecutter</code>.</p> <p>Usage:</p> <pre><code>mlcube create [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code>, <code>-h</code> boolean Show help message and exit. <code>False</code>"},{"location":"getting-started/cli/#mlcube-describe","title":"mlcube describe","text":"<p>Describe this MLCube.</p> <p>Usage:</p> <pre><code>mlcube describe [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--mlcube</code> text Path to an MLCube project. It can be a directory path, or a path to an MLCube configuration file. When it is a directory path, MLCube runtime assumes this directory is the MLCube root directory containing <code>mlcube.yaml</code> file. When it is a file path, this file is assumed to be the MLCube configuration file (<code>mlcube.yaml</code>), and a parent directory of this file is considered to be the MLCube root directory. Default value is current directory. None <code>--help</code>, <code>-h</code> boolean Show help message and exit. <code>False</code>"},{"location":"getting-started/cli/#mlcube-inspect","title":"mlcube inspect","text":"<p>Return low-level information on MLCube objects.</p> <p>Usage:</p> <pre><code>mlcube inspect [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--mlcube</code> text Path to an MLCube project. It can be a directory path, or a path to an MLCube configuration file. When it is a directory path, MLCube runtime assumes this directory is the MLCube root directory containing <code>mlcube.yaml</code> file. When it is a file path, this file is assumed to be the MLCube configuration file (<code>mlcube.yaml</code>), and a parent directory of this file is considered to be the MLCube root directory. Default value is current directory. None <code>--platform</code> text Platform name to run MLCube on (a platform is a configured instance of an MLCube runner). Multiple platforms are supported, including <code>docker</code> (Docker and Podman), <code>singularity</code> (Singularity). Other runners are in experimental stage: <code>gcp</code> (Google Cloud Platform), <code>k8s</code> (Kubernetes), <code>kubeflow</code> (KubeFlow), ssh (SSH runner). Default is <code>docker</code>. Platforms are defined and configured in MLCube system settings file. <code>docker</code> <code>--force</code> boolean Force inspecting the MLCube object. For instance, if MLCube has not been pulled or built it, then pull or build it. <code>False</code> <code>--format</code> choice (<code>json</code> | <code>yaml</code>) Format for reporting results. <code>json</code> <code>--output-file</code>, <code>--output_file</code> text File path to store the MLCube information. Defaults to print to STDOUT None <code>--help</code>, <code>-h</code> boolean Show help message and exit. <code>False</code>"},{"location":"getting-started/cli/#mlcube-run","title":"mlcube run","text":"<p>Run MLCube task(s).</p> <p>Usage:</p> <pre><code>mlcube run [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--mlcube</code> text Path to an MLCube project. It can be a directory path, or a path to an MLCube configuration file. When it is a directory path, MLCube runtime assumes this directory is the MLCube root directory containing <code>mlcube.yaml</code> file. When it is a file path, this file is assumed to be the MLCube configuration file (<code>mlcube.yaml</code>), and a parent directory of this file is considered to be the MLCube root directory. Default value is current directory. None <code>--platform</code> text Platform name to run MLCube on (a platform is a configured instance of an MLCube runner). Multiple platforms are supported, including <code>docker</code> (Docker and Podman), <code>singularity</code> (Singularity). Other runners are in experimental stage: <code>gcp</code> (Google Cloud Platform), <code>k8s</code> (Kubernetes), <code>kubeflow</code> (KubeFlow), ssh (SSH runner). Default is <code>docker</code>. Platforms are defined and configured in MLCube system settings file. <code>docker</code> <code>--task</code> text MLCube task name(s) to run, default is <code>main</code>. This parameter can take a list of values, in which case task names are separated with comma (,). None <code>--workspace</code> text Location of a workspace to store input and output artifacts of MLCube tasks. If not specified (None), <code>${MLCUBE_ROOT}/workspace/</code> is used. None <code>--network</code> text Networking options defined during MLCube container execution. None <code>--security</code> text Security options defined during MLCube container execution. None <code>--gpus</code> text GPU usage options defined during MLCube container execution. None <code>--memory</code> text Memory RAM options defined during MLCube container execution. None <code>--cpu</code> text CPU options defined during MLCube container execution. None <code>--mount</code> choice (<code>rw</code> | <code>ro</code>) Mount options for all input parameters. These mount options override any other mount options defined for each input parameters. A typical use case is to ensure that inputs are mounted in read-only (ro) mode. None <code>-P</code>, <code>-p</code> text MLCube configuration parameter is a key-value pair. Must start with <code>-P</code> or '-p'. The dot (.) is used to refer to nested parameters, for instance, <code>-Pdocker.build_strategy=always</code>. These parameters have the highest priority and override any other parameters in system settings and MLCube configuration. None <code>--help</code>, <code>-h</code> boolean Show help message and exit. <code>False</code>"},{"location":"getting-started/cli/#mlcube-show_config","title":"mlcube show_config","text":"<p>Show effective MLCube configuration.</p> <p>Effective MLCube configuration is the one used by one of MLCube runners to run this MLCube. This configuration is built by merging (1) default runner configuration retrieved from system settings, (2) MLCube project configuration and (3) configuration parameters passed by a user on a command line (CONFIG_PARAM).</p> <p>Usage:</p> <pre><code>mlcube show_config [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--mlcube</code> text Path to an MLCube project. It can be a directory path, or a path to an MLCube configuration file. When it is a directory path, MLCube runtime assumes this directory is the MLCube root directory containing <code>mlcube.yaml</code> file. When it is a file path, this file is assumed to be the MLCube configuration file (<code>mlcube.yaml</code>), and a parent directory of this file is considered to be the MLCube root directory. Default value is current directory. None <code>--platform</code> text Platform name to run MLCube on (a platform is a configured instance of an MLCube runner). Multiple platforms are supported, including <code>docker</code> (Docker and Podman), <code>singularity</code> (Singularity). Other runners are in experimental stage: <code>gcp</code> (Google Cloud Platform), <code>k8s</code> (Kubernetes), <code>kubeflow</code> (KubeFlow), ssh (SSH runner). Default is <code>docker</code>. Platforms are defined and configured in MLCube system settings file. <code>docker</code> <code>--workspace</code> text Location of a workspace to store input and output artifacts of MLCube tasks. If not specified (None), <code>${MLCUBE_ROOT}/workspace/</code> is used. None <code>--resolve</code> boolean Resolve MLCube parameters. The <code>mlcube</code> uses OmegaConf library to manage its configuration, including configuration files, system settings files and configuration parameters provided by users on command lines. OmegaConf supports variable interpolation (when one variables depend on other variables, e.g., <code>{'docker.image': 'mlcommons/{name}:${version}'}</code>). When this flag is set to true, the <code>mlcube</code> computes actual values of all variables. <code>False</code> <code>-P</code>, <code>-p</code> text MLCube configuration parameter is a key-value pair. Must start with <code>-P</code> or '-p'. The dot (.) is used to refer to nested parameters, for instance, <code>-Pdocker.build_strategy=always</code>. These parameters have the highest priority and override any other parameters in system settings and MLCube configuration. None <code>--help</code>, <code>-h</code> boolean Show help message and exit. <code>False</code>"},{"location":"getting-started/concepts/","title":"MLCube concepts","text":""},{"location":"getting-started/concepts/#command-line-arguments","title":"Command Line Arguments","text":"<p>MLCube\u00ae runtime and MLCube runners accept multiple command line arguments. They can be classified into two categories:</p> <ul> <li>Fixed command-specific parameters such as <code>--mlcube</code>, <code>--platform</code> and <code>--task</code> for the MLCube's <code>run</code> command, or   <code>create_platform</code> and <code>rename_platform</code> for the <code>config</code> command.</li> <li>Parameters that override system settings or MLCube configuration. These parameters start with <code>-P</code> and should follow   OmegaConf's format (MLCube uses this library to manage its settings and    configurations). For instance, to override docker runner settings and instruct it to always build MLCube images,   one should provide the following command line argument: <code>-Pdocker.build_strategy=always</code>.</li> </ul> <p>These command line arguments override system settings and MLCube configuration parameters.  The Command Line Interface section provides detailed  description of MLCube commands and their arguments.</p>"},{"location":"getting-started/concepts/#effective-mlcube-configuration","title":"Effective MLCube configuration","text":"<p><code>Effective MLCube configuration</code> is the actual configuration that MLCube runners use to run MLCubes. This effective configuration is built using the following algorithm. A platform configuration for a runner is retrieved from system  settings (users provide the platform name on a command line by passing <code>--platform=PLATFORM_NAME</code> argument). Then,  the MLCube configuration is loaded from the MLCube project to run, and this configuration can override default  configuration retrieved from system settings. The source for this configuration is specified by a user on a command line using <code>--mlcube=MLCUBE_PATH</code> argument. The third source of configuration is the command line. Users can provide  configuration parameters that override default behavior of a MLCube runner, or default parameters of the MLCube project. These parameters start with <code>-P</code>, for instance, <code>-Pdocker.build_strategy=always</code>. These parameters have the highest  priority and override any other parameters loaded so far.</p>"},{"location":"getting-started/concepts/#mlcube-configuration","title":"MLCube Configuration","text":"<p><code>MLCube Configuration</code> provide MLCube-specific configuration, such as implemented <code>tasks</code> and, optionally, specific  platform (hardware) requirements, for instance, GPU and host memory required to run the tasks. This configuration  overrides system settings. For MLCubes that are distributed via GitHub (with source files), this configuration is stored in a YAML file with default location being <code>${MLCUBE_ROOT}/mlcube.yaml</code>. The  MLCube configuration  section provides detailed description.</p>"},{"location":"getting-started/concepts/#mlcube-configuration-parameter","title":"MLCube Configuration Parameter","text":"<p><code>MLCube configuration paramter</code> is a configuration parameter for MLCube runners or MLCube projects that has (usually) a type from the following set: (integer, floating point number, string, bool). Every MLCube runner and all MLCube  projects have such parameters, usually organized in a hierarchy. Users can also provide these parameters on a command line when they interact with MLCube runtime to override default values for these parameters. MLCube uses  OmegaConf library to manage its configuration. When users provide these parameters on a command line, they need to follow OmegaConf rules, in particular, nested parameters should use <code>.</code> symbol. Also, when providing these parameters on a command line, these parameters must have <code>-P</code> prefix. Several examples:  <pre><code># Overriding top level parameter. Here, the `description` is a \n# parameter in a global namespace. \n-Pdescription=\"MLCube project description\"\n\n# Overriding nested parameter. Here, the `build_strategy` is a \n# parameter defined in the `docker` namespace.   \n-Pdocker.build_strategy=always\n</code></pre></p>"},{"location":"getting-started/concepts/#mlcube-home-directory","title":"MLCube Home Directory","text":"<p><code>MLCube home directory</code> is the synonym for MLCube Root Directory.</p>"},{"location":"getting-started/concepts/#mlcube-runtime","title":"MLCube Runtime","text":"<p>The <code>MLCube Runtime</code> term is used to describe the core MLCube library with MLCube runners. MLCube runtime is responsible for managing MLCube system settings and MLCube configurations, and run MLCubes in various environments.</p>"},{"location":"getting-started/concepts/#mlcube-root-directory","title":"MLCube Root Directory","text":"<p><code>MLCube root directory</code> is the directory that contains MLCube configuration file (<code>mlcube.yaml</code>). This definition  applies to MLCubes that are distributed, for instance, via GitHub.</p>"},{"location":"getting-started/concepts/#mlcubes","title":"MLCubes","text":"<p>The term <code>MLCubes</code> (or <code>MLCube project</code> in singular form) refers to Machine Learning projects packaged and distributed  using MLCube stack.</p>"},{"location":"getting-started/concepts/#platform","title":"Platform","text":"<p>A <code>platform</code> is a configured instance of a MLCube runner. Every runner has a default configured instance with the same name as runner. For instance, the MLCube docker runner (named <code>docker</code>) has a default platform named <code>docker</code> as well. Users may find it useful to have multiple configured instances (platforms) of one MLCube runner. For instance, if a user has personal and corporate accounts in some cloud provider, they can have multiple platforms - one for each account. Users directly interact with platforms via command line argument <code>--platform</code>. System settings provide platform  configurations, and users can manually edit system settings to add new platforms, or use MLCube's runtime <code>config</code>  command to perform basic operations with system settings, such as creating a new platform. See System Settings  description for more detailed explanation of MLCube runners and platforms, and how they relate to each other.</p>"},{"location":"getting-started/concepts/#runner","title":"Runner","text":"<p><code>MLCube runners</code> are workhorses of MLCube runtime. They run MLCubes in different environments, such as docker and  singularity, remote on-prem or cloud compute nodes, and orchestration engines such as Kubernetes and KubeFlow. As part of MLCube ecosystem, we provide multiple MLCube reference runners. Users do not directly interact with MLCube runners, instead they interact with <code>platforms</code>, which are configured instances of MLCube runners.</p>"},{"location":"getting-started/concepts/#system-settings","title":"System Settings","text":"<p>MLCube <code>System Settings</code> configure MLCube and MLCube runners at a system level. The term <code>system level</code> here implies  that these settings are not tied to particular MLCubes (MLCube compliant ML projects). Instead, these settings are  used by MLCube runners on every machine where MLCube runtime is configured to use these settings. By default, system settings are stored in a YAML file with default location being <code>${MLCUBE_ROOT}/mlcube.yaml</code>. The location can be overriden by exporting the <code>MLCUBE_SYSTEM_SETTINGS</code> environment variable. Detailed description of system settings is here.</p>"},{"location":"getting-started/concepts/#task","title":"Task","text":"<p>MLCube projects expose their functionality via <code>tasks</code>. A task implements one particular function, such as downloading a machine learning dataset, preprocessing this dataset, training a machine learning model, testing a machine learning  model or registering a machine learning model with the external model registry. It's up to developers to decide how they want to organize their projects into tasks. A close analogy would be machine learning pipelines composed of multiple steps organized into directed acyclic graph. Tasks in MLCubes are like steps on these pipelines, except that MLCube  runtime at this point is not aware about task dependencies, and so the MLCube task model could be described as  <code>bag of tasks</code> (similarly to <code>bag of words</code> term used in natural language processing to describe machine learning models that do not take into account positions of words in sentences).</p> <p>The MLCube examples project implements several MLCubes, including  MNIST MLCube that implements two tasks: <code>download</code> (download MNIST dataset) and <code>train</code> (train a simple classifier).</p> <p>Users can can instruct MLCube runtime to execute a particular task or tasks by providing <code>--task</code>  command line argument:</p> <ul> <li><code>mlcube run --mlcube=. --task=download --platform=docker</code>: execute one task (<code>download</code>). </li> <li><code>mlcube run --mlcube=. --task=download,train --platform=docker</code>: execute two tasks named(<code>download</code> and <code>train</code>).</li> </ul> <p>MLCube runtime executes tasks in the order provided by users. In the above example, MLCube will run the <code>download</code> task, and then - the <code>train</code> task.</p>"},{"location":"getting-started/concepts/#workspace","title":"Workspace","text":"<p>A <code>workspace</code> is a directory where input and output artifacts are stored. By default, its location is  <code>${MLCUBE_ROOT}/workspace</code>. Users can override this parameter on a command line by providing the <code>--workspace</code> argument. Users need to provide this parameter each time they run MLCube task, even when these tasks are logically grouped into  one execution. A better alternative would be to run multiple tasks at the same time (see task section).</p>"},{"location":"getting-started/hello-world/","title":"Hello World","text":"<p>Hello World MLCube\u00ae is an example of a Docker-based MLCube.  </p>"},{"location":"getting-started/hello-world/#quickstart","title":"QuickStart","text":"<p>Get started with MLCube Docker runner with below commands.   </p>"},{"location":"getting-started/hello-world/#create-python-environment","title":"Create python environment","text":"CondaVirtualEnv <pre><code>conda create -n mlcube python=3.8\nconda activate mlcube\n</code></pre> <pre><code>virtualenv --python=3.8 .mlcube\nsource .mlcube/bin/activate\n</code></pre>"},{"location":"getting-started/hello-world/#install-mlcube-docker-runner","title":"Install MLCube Docker runner","text":"<p><pre><code>pip install mlcube-docker      # Install.\nmlcube config --get runners    # Check it was installed.\nmlcube config --list           # Show system settings for local MLCube runners.\n</code></pre> Depending on how your local system is configured, it may be required to change the following settings:</p> <ul> <li><code>platforms.docker.docker</code> (string): A docker executable. Examples are <code>docker</code>, <code>nvidia-docker</code>, <code>sudo docker</code>,   <code>podman</code> etc.</li> <li><code>platforms.docker.env_args</code> (dictionary) and <code>platforms.docker.build_args</code> (dictionary). Environmental variables   for docker run and build phases. Http and https proxy settings can be configured here.</li> </ul> <p>A custom configuration could look like: <pre><code>platforms:\n  docker:\n    docker: sudo docker\n    env_args:\n      http_proxy: http://proxy.company.com:8088\n      https_proxy: https://proxy.company.com.net:8088\n    build_args:\n      http_proxy: http://proxy.company.com:8088\n      https_proxy: https://proxy.company.com:8088\n</code></pre></p>"},{"location":"getting-started/hello-world/#run-hello-world-mlcube-example","title":"Run Hello World MLCube example","text":"<p>The hello_world MLCube is part of the mlcube_examples GitHub repository: <pre><code>git clone https://github.com/mlcommons/mlcube_examples.git \ncd ./mlcube_examples/hello_world\n</code></pre></p> <p>Run Hello World MLCube on a local machine with Docker runner. Show available tasks: <pre><code>mlcube describe\n</code></pre></p> <p>Run Hello World example tasks. Very first run can take some time to download (or build) the MLCube docker image: <pre><code># No output expected.\nmlcube run --mlcube=. --task=hello --platform=docker\n\n# No output expected.\nmlcube run --mlcube=. --task=bye --platform=docker\n\n# You should some log lines in this file.\ncat ./workspace/chats/chat_with_alice.txt\n</code></pre> If above mlcube runs fail (with the error message saying there is no docker image available, try to change the system settings file by changing <code>platforms.docker.build_strategy</code> to <code>auto</code>.</p>"},{"location":"getting-started/hello-world/#setup-docker","title":"Setup Docker","text":"<p>MLCube Docker runner used Docker runtime, and they must be available in the system. Installation guides for various operating systems can be found here. This example was tested on a system where users are in the docker group and run docker without <code>sudo</code>. To add yourself to a docker group, run the following: <pre><code># Add the docker group if it doesn't already exist.\nsudo groupadd docker\n\n# Add the connected user \"${USER}\" to the docker group. Change \n# the user name to match your preferred user.\nsudo gpasswd -a ${USER} docker\n\n# Restart the Docker daemon.\nsudo service docker restart\n\n# Either do a `newgrp docker` or log out/in to activate the changes to groups.\nnewgrp docker \n</code></pre></p>"},{"location":"getting-started/hello-world/#configuring-hello-world-mlcube","title":"Configuring Hello World MLCube","text":"<p>Cubes need to be configured before they can run. MLCube runners do that automatically, and users do not need to run the configure step manually. If for some reason this needs to be done, for instance, to pre-build or pull docker images (if these processes take too much time), MLCube runtime implements <code>configure</code> command. The Hello World cube is a  Docker-based cube, and users can configure the MLCube by running the following command: <pre><code>mlcube configure --mlcube=. --platform=docker\n</code></pre> The Docker runner will build or will pull the docker image for the Hello World cube. As it is mentioned above, this step is optional and is only required when MLCubes need to be rebuilt. This can happen when users change implementation files and want to re-package their ML project into MLCube. In other situations, MLCube runners can auto-detect if <code>configure</code> command needs to be run before running MLCube tasks.</p>"},{"location":"getting-started/hello-world/#running-hello-world-mlcube","title":"Running Hello World MLCube","text":"<p>In order to run the Hello World cube, users need to provide the path to the root directory of the cube, platform and task names. Run the following two commands one at a time: <pre><code>cat ./workspace/chats/chat_with_alice.txt\n\nmlcube run --mlcube=. --platform=docker --task=hello\ncat ./workspace/chats/chat_with_alice.txt\n\nmlcube run --mlcube=. --platform=docker --task=bye\ncat ./workspace/chats/chat_with_alice.txt\n</code></pre> Hello World creates a file <code>workspace/chats/chat_with_alice.txt</code> that contains the following: <pre><code>[2020-09-03 09:13:14.236945]  Hi, Alice! Nice to meet you.\n[2020-09-03 09:13:20.749831]  Bye, Alice! It was great talking to you.\n</code></pre></p>"},{"location":"getting-started/hello-world/#modifying-mlcube-tasks","title":"Modifying MLCube tasks","text":""},{"location":"getting-started/hello-world/#override-parameters-on-a-command-line","title":"Override parameters on a command line","text":"<p>One way to change the parameters of MLCubes is to override them on a command line. Create a new file <code>workspace/names/mary.txt</code> with the following content: <code>Mary</code>. Then, run the following: <pre><code>mlcube run --mlcube=. --platform=docker --task=hello name=names/mary.txt chat=chats/chat_with_mary.txt\ncat workspace/chats/chat_with_mary.txt\n\nmlcube run --mlcube=. --platform=docker --task=bye name=names/mary.txt chat=chats/chat_with_mary.txt\ncat workspace/chats/chat_with_mary.txt\n</code></pre> You should observe the output similar to this one: <pre><code>[2021-09-30 18:49:46.896509]  Hi, Mary! Nice to meet you.\n[2021-09-30 18:49:56.883266]  Bye, Mary! It was great talking to you.\n</code></pre></p>"},{"location":"getting-started/hello-world/#providing-a-better-greeting-message","title":"Providing a better greeting message","text":"<p>Because how Hello World cube was implemented, the greeting message is always the following: <code>Nice to meet you.</code>. We will update the implementation so that if this is not the first time Alice says <code>hello</code>, the  MLCube will respond: <code>Nice to  see you again.</code>.</p> <p>Modify the file <code>hello_world.py</code>. Update the function named <code>get_greeting_message</code> on line 14. It should have the following implementation: <pre><code>import os\n\ndef get_greeting_message(chat_file: str) -&gt; str:\n    return \"Nice to meet you.\" if not os.path.exists(chat_file) else \"Nice to see you again.\"\n</code></pre> Reconfigure the MLCube: <pre><code>mlcube configure --mlcube=. --platform=docker\n</code></pre> And run two <code>hello</code> tasks again: <pre><code>rm ./workspace/chats/chat_with_alice.txt\n\nmlcube run --mlcube=. --platform=docker --task=hello,bye\nmlcube run --mlcube=. --platform=docker --task=hello,bye\n\ncat ./workspace/chats/chat_with_alice.txt\n</code></pre> The MLCube recognized it was not the first time it talked to Alice, and changed the greeting: <pre><code>[2021-09-30 20:04:36.977032]  Hi, Alice! Nice to meet you.\n[2021-09-30 20:04:40.851157]  Bye, Alice! It was great talking to you.\n[2021-09-30 20:04:47.228554]  Hi, Alice! Nice to see you again.\n[2021-09-30 20:04:51.031609]  Bye, Alice! It was great talking to you.\n</code></pre></p>"},{"location":"getting-started/mlcube-configuration/","title":"MLCube Configuration","text":"<p>MLCube\u00ae configuration provides information about MLCube's authors, requirements and tasks. This is example configuration for the MNIST MLCube:</p> <pre><code>name: mnist\ndescription: MLCommons MNIST MLCube example\nauthors:\n  - {name: \"First Second\", email: \"first.second@company.com\", org: \"Company Inc.\"}\n\nplatform:\n  accelerator_count: 0\n  accelerator_maker: NVIDIA\n  accelerator_model: A100-80GB\n  host_memory_gb: 40\n  need_internet_access: True\n  host_disk_space_gb: 100\n\ndocker:\n  image: mlcommons/mnist:0.0.1\n\nsingularity:\n  image: mnist-0.0.1.sif\n\ntasks:\n  download:\n    parameters:\n      inputs:\n        data_config: {type: file, default: data.yaml}\n      outputs:\n        data_dir: {type: directory, default: data}\n        log_dir: {type: directory, default: logs}\n  train:\n    parameters:\n      inputs:\n        data_dir: {type: directory, default: data}\n        train_config: {type: file, default: train.yaml}\n      outputs:\n        log_dir: {type: directory, default: logs}\n        model_dir: {type: directory, default: model}\n</code></pre>"},{"location":"getting-started/mlcube-configuration/#metadata","title":"Metadata","text":"<p>MLCube configuration can contain metadata about MLCube developers. The following fields are allowed:</p> <ul> <li><code>name (type=string)</code>  MLCube name.</li> <li><code>description (type=string)</code>  MLCube description.</li> <li><code>authors (type=list)</code>  List of MLCube developers / authors. Each item is a dictionary with the following fields:</li> <li><code>name (type=string)</code>  Author full name.</li> <li><code>email (type=string)</code>  Author email.</li> <li><code>org (type=string)</code>  Author affiliation.</li> </ul>"},{"location":"getting-started/mlcube-configuration/#resources","title":"Resources","text":"<p>The <code>platform</code> section (optional) can provide information about resources that MLCubes require. </p> <p>Warning</p> <p>Parameters defined in this section are not supported yet by MLCube runners. </p> <p>This section is intended to be used by MLCube  runners. For instance, cloud runners can use information about accelerators, disk space and memory to provision appropriate resources. The exact fields of this section are to be defined.</p>"},{"location":"getting-started/mlcube-configuration/#tasks","title":"Tasks","text":"<p>This <code>tasks</code> section provides description of what's implemented in an MLCube. This section is a dictionary that maps a task name to a task configuration. In the example above, two tasks are defined - <code>download</code> and <code>train</code>. </p> <p>Each task configuration is a dictionary with two parameters:</p> <ul> <li><code>entrypoing (type=string)</code> Optional task-specific entrypoint (e.g., executable script, for instance, inside an MLCube    container). If not present, it is assumed that global entry point is defined (for instance, via Docker's entry point    configuration - see example).</li> <li><code>parameters (type=dictionary)</code> Optional specification of input and output parameters. If present, can contain two   optional fields - <code>inputs</code> and <code>outputs</code>. Each field specifies task's input and output parameters. This specification   is a dictionary mapping from a parameter name to a parameter description. In the above example, the <code>download</code> task   defines one input parameter (<code>data_config</code>) and two output parameters (<code>data_dir</code> and <code>log_dir</code>). Each parameter    description is a dictionary with the following fields:<ul> <li><code>type (type=string)</code> Specifies parameter type, and must be one of <code>file</code> or <code>directory</code>.</li> <li><code>default (type=string)</code> Parameter value: path to a directory of path to a file. <ul> <li>Paths can contain <code>~</code> (user home directory) and environment variables (e.g., <code>${HOME}</code>). MLCube does not    encourage the use of environment variables  since this makes MLCube less portable and reproducible. The use    of <code>~</code> should be OK though.</li> <li>Paths can be absolute or relative. Relative paths are always relative to current MLCube workspace directory.    In the example above,  the <code>data_conig</code> parameter's default value for the <code>download</code> task is a short form of    <code>${workspace}/data.yaml</code>. </li> </ul> </li> <li><code>opts (type=string)</code> This optional field specifies file or path access options (e.g., mount options for container   runtimes). Valid values are <code>rw</code> (read and write) and <code>ro</code> (read only). When parameter is a file, these options    are set for a volume associated with the file's parent directory. When read-only option is specified for   an output parameter, MLCube runner will use it and will log to a log file. When conflicting options are    found, MLCube will log a warning message and will use the <code>rw</code> option. </li> </ul> </li> </ul>"},{"location":"getting-started/mlcube-configuration/#examples","title":"Examples","text":"<p>More example configurations of MLCubes can be found in the mlcube_examples  repository. In particular,  the getting-started example shows the use of the entrypoint  specification.</p>"},{"location":"getting-started/mnist/","title":"MNIST","text":"<p>The MNIST dataset is a collection of 60,000 handwritten digits widely used for training statistical, Machine Learning (ML) and Deep Learning (DL) models. The MNIST MLCube\u00ae example demonstrates how data scientists, ML and DL researchers and developers can distribute their ML projects (including training, validation and inference code) as MLCube cubes. MLCube establishes a standard to package user workloads, and provides unified command line interface. In addition, MLCube provides a number of reference  runners - python packages that can run cubes on  different platforms including  Docker, Singularity, KubeFlow and several others.</p> <p>Example</p> <p>A data scientist has been working on a machine learning project. The goal is to train a simple neural network to classify the collection of 60,000 small images into 10 classes.</p> <p>Information</p> <p>The source files for this MNIST example can be found on GitHub in MLCube  Example repository.</p>"},{"location":"getting-started/mnist/#mnist-training-code","title":"MNIST training code","text":"<p>Training an ML model is a process involving multiple steps such as downloading data, analyzing and cleaning data,  splitting data into train/validation/test data sets, running hyperparameter optimization experiments and performing final model testing. MNIST dataset is a relatively small and well studied dataset that provides standard train/test split. In this simple example a developer needs to implement two steps - (1) downloading data and (2) training a model. We call these steps as <code>tasks</code>. Each task requires several parameters, such as a URL of the data set that we need to download, location on a local disk where the data set will be downloaded to, path to a directory that will contain training artifacts such as log files, training snapshots and Machine Learning models. We can characterize these two tasks in the following way:  </p> <ul> <li><code>Download</code> task:<ul> <li>Inputs: A yaml file (<code>data_config</code>) with two parameters - dataset URI and dataset hash.</li> <li>Outputs: Directory to serialize the data set (<code>data_dir</code>) and directory to serialize log files (<code>log_dir</code>).</li> </ul> </li> <li><code>Training</code> task:<ul> <li>Inputs: Directory with MNIST data set (<code>data_dir</code>), training hyper-parameters defined in a file    (<code>train_config</code>).</li> <li>Outputs:  Directory to store training results (<code>model_dir</code>) and directory to store log files (<code>log_dir</code>).</li> </ul> </li> </ul> <p>We have intentionally made all input/output parameters to be file system artifacts. By doing so, we support reproducibility. Instead of command line arguments that can easily be lost, we store them in files. There are many ways to implement the MNIST example. For simplicity, we assume the following:  </p> <ul> <li>We use one python file.  </li> <li>Task name (download, train) is a command line positional parameter.  </li> <li>Both tasks write logs, so it makes sense to add a parameter that defines a directory for log files.  </li> <li>The download task accepts additional data directory parameter.   </li> <li>The train task accepts such parameters as data and model directories, path to a file with hyper-parameter.</li> <li>Configurable hyper-parameters are: (1) optimizer name, (2) number of training epochs and (3) global batch size. </li> </ul> <p>Then, our implementation could look like this. Parse command line arguments and identify a task to run. If it is  the <code>download</code> task, call a function that downloads data sets. If it is the <code>train</code> task, train a model. This is sort  of single entrypoint implementation where we run one script asking to perform various tasks. We run our script (mnist.py) in the following way: <pre><code>python mnist.py download --data_config=PATH --data_dir=PATH --log_dir=PATH\npython mnist.py train --train_config=PATH --data_dir=PATH --model_dir=PATH --log_dir=PATH\n</code></pre></p>"},{"location":"getting-started/mnist/#mlcube-implementation","title":"MLCube implementation","text":"<p>Packaging our MNIST training script as a MLCube is done in several steps. We will be using a directory-based  cube where a directory is structured in a certain way and contains specific files that make it MLCube compliant. We need to create an empty directory on a local disk. Let's assume we call it <code>mnist</code> and we'll use <code>{MLCUBE_ROOT}</code> to denote a full path to this directory. This is called an MLCube root directory. At this point this directory is empty: <pre><code>mnist/\n</code></pre></p>"},{"location":"getting-started/mnist/#build-location","title":"Build location","text":"<p>The MLCube root directory will contain project source files, resources required for training, other files to recreate  run time (such as requirements.txt, docker and singularity recipes etc.). We need to copy two files: mnist.py that  implements training and requirements.txt that lists python dependencies. By doing so, we are enforcing reproducibility.  A developer of this MLCube wants to make it easier to run their training workload in a great variety of environments  including universities, commercial companies, HPC-friendly organizations such as national labs. One way to achieve it is  to use container runtime such as docker or singularity. So, we'll provide both docker file and singularity recipe that  we'll put into the MLCube root directory as well. Thus, we'll make this directory a build context. For reasons that we will explain later, we also need to add .dockerignore file (that contains single line - <code>workspace/</code>). The MLCube  directory now looks like: <pre><code>mnist/\n  .dockerignore\n  Dockerfile\n  mnist.py\n  requirements.txt\n  Singularity.recipe\n</code></pre> A good test at this point would be to ensure that project is runnable from the build directory, and docker and  singularity images can be built.  </p>"},{"location":"getting-started/mnist/#mlcube-definition-file","title":"MLCube definition file","text":"<p>At this point we are ready to create a cube definition file. This is the first definition file that makes a folder to be an MLCube folder. This is a YAML file that provides information such as name, author, version, named as <code>mlcube.yaml</code> and located in the cube root directory . The most important section is the one that lists what tasks are implemented in this cube: <pre><code># Name of this MLCube.\nname: mnist\n# Brief description for this MLCube.\ndescription: MLCommons MNIST MLCube example\n# List of authors/developers. \nauthors:\n  - name: \"First Second\"\n    email: \"first.second@company.com\"\n    org: \"Company Inc.\"\n\n# Platform description. This is where users can specify MLCube resource requirements, such as \n# number of accelerators, memory and disk requirements etc. The exact structure and intended \n# usage of information in this section is work in progress. This section is optional now.\nplatform:\n  accelerator_count: 0\n  accelerator_maker: NVIDIA\n  accelerator_model: A100-80GB\n  host_memory_gb: 40\n  need_internet_access: True\n  host_disk_space_gb: 100\n\n# Configuration for docker runner (additional options can be configured in system settings file).\ndocker:\n  image: mlcommons/mnist:0.0.1\n\n# Configuration for singularity runner (additional options can be configured in system settings \n# file).\nsingularity:\n  image: mnist-0.0.1.simg\n\n# Section where MLCube tasks are defined.\ntasks:\n  # `Download` task. It has one input and two output parameters.\n  download:\n    parameters:\n      inputs: {data_config: data.yaml}\n      outputs: {data_dir: data/, log_dir: logs/}\n  # `Train` task. It has two input and two output parameters.\n  train:\n    parameters:\n      inputs: {data_dir: data/, train_config: train.yaml}\n      outputs: {log_dir: logs/, model_dir: model/}\n</code></pre> At this point, the directory looks like: <pre><code>mnist/\n  .dockerignore\n  Dockerfile\n  mlcube.yaml\n  mnist.py\n  requirements.txt\n  Singularity.recipe\n</code></pre></p>"},{"location":"getting-started/mnist/#workspace","title":"Workspace","text":"<p>The workspace is a directory inside cube (<code>workspace</code>) where, by default, input/output file system artifacts are stored. There are multiple reasons to have one. One is to formally have default place for data sets, configuration and log files etc. Having all these parameters in one place makes it simpler to run cubes on remote hosts and then sync results back to users' local machines.</p> <p>We need to be able to provide URI and hash of the MNIST dataset, collection of hyper-parameters and formally define a  directory to store logs, models and MNIST data set. To do so, we create the directory tree <code>workspace/</code>, and then create  two files with the following content (<code>data.yaml</code>): <pre><code>uri: https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\nhash: 731c5ac602752760c8e48fbffcf8c3b850d9dc2a2aedcf2cc48468fc17b673d1\n</code></pre> and <code>train.yaml</code>: <pre><code>optimizer: \"adam\"\ntrain_epochs: 5\nbatch_size: 32\n</code></pre> At this point, the cube directory looks like: <pre><code>mnist/\n  workspace/\n    data.yaml\n    train.yaml\n  .dockerignore\n  Dockerfile\n  mlcube.yaml\n  mnist.py\n  requirements.txt\n  Singularity.recipe\n</code></pre></p>"},{"location":"getting-started/mnist/#mnist-mlcube-directory-structure-summary","title":"MNIST MLCube directory structure summary","text":"<pre><code>mnist/\n  workspace/          # Default location for data sets, logs, models, parameter files.\n    data.yaml         #   URI and hash of MNIST dataset.\n    train.yaml        #   Train hyper-parameters.\n  .dockerignore       # Docker ignore file that prevents workspace directory to be sent to docker server.\n  Dockerfile          # Docker recipe.\n  mlcube.yaml         # MLCube definition file.\n  mnist.py            # Python source code training simple neural network using MNIST data set.\n  requirements.txt    # Python project dependencies.\n  Singularity.recipe  # Singularity recipe.\n</code></pre>"},{"location":"getting-started/mnist/#running-mnist-mlcube","title":"Running MNIST MLCube","text":"<p>We need to set up the Python virtual environment. These are the steps outlined in the <code>Introduction</code> section except we  do not clone GitHub repository with the example MLCube cubes. </p> <p>Create python environment.</p> CondaVirtualEnv <pre><code>conda create -n mlcube python=3.8\nconda activate mlcube\n</code></pre> <pre><code>virtualenv --python=3.8 .mlcube\nsource .mlcube/bin/activate\n</code></pre> <p>Install MLCube Docker and Singularity runners. <pre><code>pip install mlcube mlcube-docker mlcube-singularity\n</code></pre></p> <p>Attention</p> <p>Before running MNIST cube below, it is probably a good idea to remove tasks' outputs from previous runs that are located in the <code>workspace</code> directory. All files and directories except <code>data.yaml</code> and <code>train.yaml</code> files can  be removed.</p>"},{"location":"getting-started/mnist/#docker-runner","title":"Docker Runner","text":"<p>Configure MNIST cube (this is optional step, docker runner checks if image exists, and if it does not, runs <code>configure</code> phase automatically): <pre><code>mlcube configure --mlcube=. --platform=docker\n</code></pre></p> <p>Run two tasks - <code>download</code> (download data) and <code>train</code> (train tiny neural network): <pre><code>mlcube run --mlcube=. --platform=docker --task=download\nmlcube run --mlcube=. --platform=docker --task=train\n</code></pre></p>"},{"location":"getting-started/mnist/#singularity-runner","title":"Singularity Runner","text":"<p>Configure MNIST cube: <pre><code>mlcube configure --mlcube=. --platform=singularity\n</code></pre></p> <p>Run two tasks - <code>download</code> (download data) and <code>train</code> (train tiny neural network): <pre><code>mlcube run --mlcube=. --platform=singularity --task=download\nmlcube run --mlcube=. --platform=singularity --task=train\n</code></pre></p>"},{"location":"getting-started/system-settings/","title":"MLCube System Settings","text":"<p>MLCube\u00ae system settings configure MLCube and MLCube runners at a system level. The term <code>system level</code> here implies  that these settings are not tied to particular MLCubes (MLCube compliant ML projects). Instead, these settings are used  by MLCube runners on every machine where MLCube runtime is configured to use these settings.</p>"},{"location":"getting-started/system-settings/#introduction","title":"Introduction","text":"<p>When MLCube runners run MLCubes, they need to know not only the content of MLCubes (tasks that MLCubes provide), but  also non-standard or custom settings of a user environment. Effective MLCube configuration that MLCube runners end up using is constructed by merging configurations from the following sources:</p> <ul> <li><code>System settings</code> provide non-standard and/or user-specific parameters for MLCube runners. For instance, in system   settings users can indicate that they are required to use <code>sudo</code> to run docker. Or they can configure MLCube SSH or   GCP (Google Cloud Platform) runners with their credentials to be able to run MLCubes on specific remote servers,    either on-prem, or in the cloud.</li> <li><code>MLCube configuration</code> provide MLCube-specific configuration, such as implemented tasks and, optionally, specific   platform (hardware) requirements, for instance, GPU and host memory required to run the tasks. This configuration   overrides system settings.</li> <li><code>Command line parameters</code> that users provide when they run MLCubes. These parameters have the highest priority and    override system settings and MLCube configuration.</li> </ul>"},{"location":"getting-started/system-settings/#location","title":"Location","text":"<p>MLCube system settings are stored in a YAML file. Default location of this file is <code>${HOME}/mlcube.yaml</code>. This file is created or updated every time users run any of MLCube commands. When users install a new MLCube runner (for instance,  the singularity runner <code>pip install mlcube-singularity</code>), MLCube will update the system settings file with this new  runner next time MLCube runs. Users can directly modify this file. In addition, MLCube runtime provides <code>config</code>  command (<code>mlcube config --help</code>) to perform typical operations, such as creating a new MLCube runner configuration off  existing one. Users can override the location of this file by defining <code>MLCUBE_SYSTEM_SETTINGS</code> environment variable. </p>"},{"location":"getting-started/system-settings/#mlcube-system-settings_1","title":"MLCube System Settings","text":"<p>The MLCube system settings are stored in a YAML file. This file has the following schema: <pre><code>runners:\n  # A dictionary with metadata on installed MLCube runners. This section is updated (if \n  # necessary) every time MLCube runs (this means that this section is not updated once \n  # a new runner is installed). Every key in this dictionary is a runner name (must be \n  # unique across all MLCube runners), and every value is (usually) a dictionary providing \n  # runner metadata. In general, it is runner-specific. This section does not provide a \n  # specific configuration for instances of MLCube runners, and users should not modify \n  # content of this section - it is maintained automatically by MLCube runtime.\n  docker:\n    # MLCube provides several reference runners including docker and singularity runners. \n    # All reference runners are implemented in Python and are distributed as separate python \n    # packages on pypi (e.g., `pip install mlcube-docker`). All these reference runners use \n    # the same metadata schema. Their metadata is a dictionary with just one field - `pkg`. \n    # Names of MLCube runners in this section are not directly exposed to users via command \n    # line API.\n    pkg: mlcube_docker\n    # All MLCube reference runners are described with a dictionary with one field (`pkg`) \n    # that points to a Python package name.\n\nplatforms:\n  # This section (a dictionary) configures instances of MLCube runners. Why there might be \n  # more than one instance of a particular runner? For instance, users might have two Google \n  # Cloud Platform accounts - personal and corporate. Or they might have access to a number \n  # of on-prem compute nodes via ssh, and so they will have respective number of MLCube SSH \n  # runner instances configured here. There is always a default MLCube runner instance that \n  # has the same name as the runner itself (e.g., for Docker runner the name of a default \n  # MLCube docker runner is `docker`). This default section is created automatically by \n  # MLCube runtime if it does not exist.\n  # Every MLCube runner has its own schema (see MLCube runners documentation) with its own \n  # unique set of configuration parameters.\n  # Names of MLCube runner instances defined here are directly exposed to users via command \n  # line argument `--platform`:\n  #    - By default, a default MLCube runner instance is configured with the same name as \n  #      its MLCube runner class name: docker, singularity etc.\n  #    - When users configure their own unique MLCube runner instances (either via `mlcube \n  #      config create_platform` command, or manually modifying this file(*)), these instances \n  #      become available to use, i.e., something like is possible:\n  #        $ mlcube run --mlcube=. --task=train --platform=my_mlcube_runner_instance_name\n  #    (*): To configure a new runner instance manually, duplicate default configuration with \n  #         a new name and change its parameters.\n  singularity:\n    # This is the example of a default configuration for a MLCube reference singularity runner.\n    # This runner instance, as any other instance, defines the `runner` key which servers as \n    # a foreign key to the `runners` section.\n    runner: singularity\n    # MLCube runner class (defined in `runners` section).\n    image: ${singularity.image}\n    # Image name, usually defined in MLCube configuration file.\n    image_dir: ${runtime.workspace}/.image\n    # Default build directory for MLCubes distributed with sources.\n    singularity: singularity\n    # Singularity executable.\n    build_args: --fakeroot\n    # Build arguments.\n    build_file: Singularity.recipe\n    # Default Singularity build file for MLCubes distributed with sources\n\n  singularity-1.5.3:\n    # This is an example of another MLCube singularity runner instance. Maybe, a user has \n    # an outdated version that requires sudo and does not support --fakeroot argument.\n    # Then, this user use this name on a command line to run MLCubes with singularity runner:\n    #        $ mlcube run --mlcube=. --task=train --platform=singularity-1.5.3\n    # BTW, users can create this section by running the following command (they need to edit \n    # it manually though anyway):\n    #        $ mlcube config create_platform singularity singularity-1.5.3 \n    runner: singularity\n    image: ${singularity.image}\n    image_dir: ${runtime.workspace}/.image\n    singularity: sudo singularity\n    build_args:\n    build_file: Singularity.recipe\n</code></pre></p>"},{"location":"runners/","title":"Runners","text":"<p>MLCube\u00ae runners run MLCube cubes on one or multiple platforms. Examples of platforms are Docker and Singularity  containers, Kubernetes, remote hosts, virtual machines in the cloud, etc. Every runner has a fixed set of configuration parameters that users can change to configure MLCubes and runners for their environments. Concretely, runners can take information from three different sources:</p> <ul> <li>MLCube configuration files that    are located in the root directory of each file-system based MLCube. Parameters in these files configure generic    parameters common for all environments, such as for instance, docker image names.</li> <li>MLCube system settings file that is    located (by default) in the user home directory (<code>~/mlcube.yaml</code>). This file is created automatically, and can be    used to configure parameters common for all MLCubes in a particular environments. They can include docker executable,    GPU and CPU docker arguments, user SSH and cloud credentials, etc.</li> <li>Optionally, runners can use parameters defined in <code>platform</code> section of MLCube configuration file. This section    usually contains information about such requirements as memory and persistent storage requirements, number of   accelerators etc.</li> </ul> <p>Important</p> <p>MLCube standard requires that all runners implement mandatory functionality. All reference runners implement it. Users can develop their own runners to meet their specific requirements, such as security, authentication and authorization policies, and others.   </p>"},{"location":"runners/#reference-mlcube-runners","title":"Reference MLCube runners","text":"<p>Reference runners are:</p> <ul> <li>Docker Runner:    runs cubes locally using docker runtime.  </li> <li>GCP Runner:    runs cubes in Google cloud.  </li> <li>Kubernetes Runner:    runs cubes in Kubernetes.  </li> <li>Kubeflow Runner:   runs cubes using Kubeflow.  </li> <li>Singularity Runner:    runs cubes using singularity runtime.    </li> <li>SSH Runner:   runs cubes on remote hosts. SSH Runner uses other runners, such as Docker or Singularity runners, to run cubes on    remote hosts.  </li> </ul>"},{"location":"runners/#runner-commands","title":"Runner commands","text":"<p>Each runner exposes mandatory and optional functionality through a set of commands. This is similar to, for instance, how Git implements its CLI (<code>git</code> followed by a specific command such as <code>checkout</code>, <code>pull</code>, <code>push</code> etc.). Mandatory MLCube runner commands are <code>configure</code> and <code>run</code>:  </p> <ul> <li><code>configure</code>: Configure MLCube. Exact functionality depends on a runner type, but the goal is to ensure that    a cube is ready to run. The following are the examples of what can be done at configure phase: build docker or    singularity container, create python virtual environment, allocate and configure virtual machine in the cloud, copy   cube to a remote host etc. Once configuration is successfully completed, it is assumed a runner can run that cube.  </li> <li><code>run</code>: Run tasks defined in MLCube.  </li> </ul> <p>Reference runners recognize three parameters - mlcube, platform and task.</p> <ul> <li><code>mlcube</code>: Path to a cube root directory. In future versions, this can be a URI with a specific protocol. Runners   could support various MLCube implementations (excluding reference directory-based) such as docker/singularity    containers, GitHub repositories, compressed archives and others.  </li> <li><code>platform</code>: Name of a platform. By default, runners create standard platform configurations in MLCube system settings   file with predefined names. Users can change those names and use them on a command line. For instance, they can have   different names for an 8-way GPU server and a simple CPU-based server for SSH runner.  </li> <li><code>task</code>: Name of a task, or comma-separated list of tasks.  </li> </ul>"},{"location":"runners/#command-line-interface","title":"Command line interface","text":"<p>One way to run a MLCube is to follow the following template supported by all reference runners: <pre><code>mlcube COMMAND --mlcube=MLCUBE_ROOT_DIRECTORY --platform=PLATFORM_NAME --task=TASK_NAME\n</code></pre></p> <p>Example command to configure MNIST Docker-based MLCube: <pre><code>mlcube configure --mlcube=examples/mnist --platform=docker\n</code></pre></p> <p>Example command to run two tasks implemented by the MNIST Docker-based MLCube: <pre><code>mlcube run --mlcube=examples/mnist --platform=docker --task=download\nmlcube run --mlcube=examples/mnist --platform=docker --task=train\n</code></pre></p>"},{"location":"runners/#configuration-subsystem","title":"Configuration subsystem","text":"<p>Runners are configured using information from three different sources:</p> <ul> <li>The base configuration comes from the    system settings file. By default,    the location of this file is <code>${HOME}/mlcube.yaml</code>. It is created automatically whenever a user runs <code>mlcube</code> command    line tool. The purpose of this file is to provide system-wide configuration for runners that are specific to user and    their environment. This is kind of information that should not generally present in MLCube configuration files    (next item). It should include such information as docker executable (docker, sudo docker, nvidia-docker, podman,    etc.), docker-specific runtime arguments, user credentials for GCP and remote hosts, information about    remote hosts etc.</li> <li>The MLCube configuration file    that is available with each MLCube cube. This file contains (as of now) such parameters, as docker and singularity    image names, MLCube resource requirements and tasks. This information overrides information from system settings file.</li> <li>Configuration that is provided on a command line. Users are allowed (but not encouraged) to override parameters on   the fly when they run MLCube cubes.</li> </ul>"},{"location":"runners/#mlcube-system-settings-file","title":"MLCube System settings file","text":"<p>Example of MLCube system settings file (<code>${HOME}/mlcube.yaml</code>) is the following. As it was mentioned above, it is created automatically by searching packages that start with <code>mlcube_</code>. Such packages must provide <code>get_runner_class</code> function that must return a runner class derived from <code>Runner</code>.  <pre><code># This section maps a runner name to a runner package. This is one way how developers can plug in\n# their custom runners. Python package, or this type of association, could be one of many ways to\n# implement runners. \nrunners:\n  docker:                      # MLCube Docker reference runner\n    pkg: mlcube_docker\n  gcp:                         # MLCube Google Cloud Platform reference runner\n    pkg: mlcube_gcp\n  k8s:                         # MLCube Kubernetes reference runner\n    pkg: mlcube_k8s\n  kubeflow:                    # MLCube KubeFlow reference runner\n    pkg: mlcube_kubeflow\n  singularity:                 # MLCube Singularity reference runner\n    pkg: mlcube_singularity\n  ssh:                         # MLCube SSH reference runner\n    pkg: mlcube_ssh\n# This section defines configurations for the above runners. It is a dictionary mapping platform\n# name to a runner configuration. These names could be any names. For instance, users can have \n# two platforms for an SSH runner pointing to two different remote hosts. The platform names are\n# those passed to mlcube tool using `--platform` command line argument.\nplatforms:\n  # Docker runner configuration. The only parameter that is supposed to be present in MLCube\n  # configuration files is image name (`image`). For other parameters, see Docker Runner\n  # documentation page.\n  docker:\n    runner: docker\n    image: ${docker.image}\n    docker: docker\n    env_args: {}\n    gpu_args: ''\n    cpu_args: ''\n    build_args: {}\n    build_context: .\n    build_file: Dockerfile\n    build_strategy: pull\n  # Google Cloud Platform runner. None of these configuration parameters are supposed to be \n  # present in MLCube configuration files.  For other parameters, see GCP Runner documentation \n  # page.\n  gcp:\n    runner: gcp\n    gcp:\n      project_id: ''\n      zone: ''\n      credentials: ''\n    instance:\n      name: ''\n      machine_type: ''\n      disk_size_gb: ''\n    platform: ''\n  # Kubernetes runner. None of these configuration parameters are supposed to be present in \n  # MLCube configuration files.  For other parameters, see Kubernetes Runner documentation page.\n  k8s:\n    runner: k8s\n    pvc: ${name}\n    image: ${docker.image}\n    namespace: default\n  # Kubeflow runner. None of these configuration parameters are supposed to be present in \n  # MLCube configuration files.  For other parameters, see Kubeflow Runner documentation page.\n  kubeflow:\n    runner: kubeflow\n    image: ${docker.image}\n    pvc: ???\n    namespace: default\n    pipeline_host: ''\n  # Singularity runner configuration. The only parameter that is supposed to be present in MLCube\n  # configuration files is image name (`image`). For other parameters, see Singularity Runner\n  # documentation page.\n  singularity:\n    runner: singularity\n    image: ${singularity.image}\n    image_dir: ${runtime.workspace}/.image\n    singularity: singularity\n    build_args: --fakeroot\n    build_file: Singularity.recipe\n  # SSH runner. None of these configuration parameters are supposed to be present in \n  # MLCube configuration files.  For other parameters, see SSH Runner documentation page.\n  ssh:\n    runner: ssh\n    host: ''\n    platform: ''\n    remote_root: ''\n    interpreter: {}\n    authentication: {}\n# Dedicated section to define future data `storage` layer. It's work in progress.\nstorage: {}\n</code></pre></p> <p>Users can and should update configuration parameters according to their environment. Also, please backup this file regularly. One possibility is to move this file to a location that is regularly snapshoted. When non-standard path is used, users must define a <code>MLCUBE_SYSTEM_SETTINGS</code> environment variable that points to this new location.</p> <p>Users can also duplicate runner sections assigning names accordingly, like it was mentioned above. For instance, users can have two ssh sections one for each different host: <pre><code>platforms:\n  my_dev_server_1:\n    runner: ssh\n    # Other parameters ...\n  my_dev_server_2:\n    runner: ssh\n    # Other parameters ...\n</code></pre> and then <pre><code>mlcube run --mlcube=. --task=MY_TASK --platform=my_dev_server_2\n</code></pre></p> <p>MLCube runtime provides minimal functionality to interact with system settings file: <pre><code># Print system settings file\nmlcube config --list\n\n# Query a value associated with the particular key\nmlcube config --get runners\nmlcube config --get platforms.docker\n\n# Create a new fresh platform for this runner\nmlcube config --create-platform ssh my_dev_server_1\nmlcube config --get platforms.my_dev_server_1\n\n# Rename platform\nmlcube config --rename-platform my_dev_server_1 my_dev_server_2\nmlcube config --get platforms.my_dev_server_2\n\n# Remove platform from the system settings file\nmlcube config --remove-platform my_dev_server_2\n\n# Create a new platform copying configuration of one of existing platforms.\nmlcube config --copy-platform EXISTING_PLATFORM NEW_PLATFORM\n\n#  Rename existing runner\nmlcube config --rename-runner OLD_NAME NEW_NAME\n\n# Remove runner\nmlcube config --remove-runner NAME\n</code></pre></p> <p>Attention</p> <p>Removed standard runners (MLCube reference runners) will be recreated when mlcube runs next time.</p>"},{"location":"runners/docker-runner/","title":"Docker Runner","text":"<p>Docker runner uses docker/nvidia-docker/podman to run MLCube\u00ae cubes. It supports two mandatory commands - <code>configure</code> and <code>run</code> with standard arguments - <code>mlcube</code>, <code>platform</code> and <code>task</code>. Users can configure docker runner in MLCube  configuration file, system setting file, and override parameters on a command line.</p>"},{"location":"runners/docker-runner/#configuration-parameters","title":"Configuration parameters","text":"<p>MLCube reference docker runner supports the following configuration parameters (with default values): <pre><code># Docker Image name, for instance \"mlcommons/mnist:0.0.1\"\nimage: ${docker.image}\n# Docker executable (docker, podman, sudo docker ...).\ndocker: docker\n\n# Environmental variables for run command (-e name=value).\nenv_args: {}               \n\n# Docker run arguments when ${platform.accelerator_count} &gt; 0.\ngpu_args: ''\n# Docker run arguments when ${platform.accelerator_count} == 0.\ncpu_args: ''\n\n# Docker build arguments (--build-arg name=value)\nbuild_args: {}\n# Docker build context relative to $MLCUBE_ROOT. Default is $MLCUBE_ROOT.\nbuild_context: .\n# Docker file relative to $MLCUBE_ROOT, default is `$MLCUBE_ROOT/Dockerfile`.\nbuild_file: Dockerfile\n# MLCube configuration strategy\n#   'pull': never try to build, always pull\n#   'auto': build if image not found and dockerfile found\n#   'always': build even if image found\nbuild_strategy: pull\n</code></pre></p>"},{"location":"runners/docker-runner/#configuring-mlcubes","title":"Configuring MLCubes","text":"<p>Docker runner uses <code>build_strategy</code> configuration parameter to decide on build strategy:</p> <ul> <li><code>pull</code>: always try to pull docker image, never attempt to build.</li> <li><code>auto</code>: use <code>build_context</code> and <code>build_file</code> to decide if <code>Dockerfile</code> exists. If it exists, build the image.</li> <li><code>always</code>: build docker image always when running MLCube tasks.</li> </ul> <p>Docker runner under the hood runs the following command line: <pre><code>${docker.docker} build ${docker.build_args} -t ${docker.image} -f ${recipe} ${context}\n</code></pre> where:</p> <ul> <li><code>${docker.docker}</code> is the docker executable.</li> <li><code>${docker.build_args}</code> docker build arguments.</li> <li><code>${docker.image}</code> is the docker image name.  </li> <li><code>${recipe}</code> is the <code>${docker.build_file}</code> relative to context</li> <li><code>${context}</code> is the <code>${docker.build_context}</code> relative to MLCube root directory.</li> </ul> <p>Users do not need to run the configure command explicitly, docker runner uses the following logic to decide what to do before running any task. If strategy is <code>always</code>, build the docker image. Else, if docker image exists, do nothing, else build or pull depending on what strategy is and if Dockerfile exists in MLCube directory. </p>"},{"location":"runners/docker-runner/#running-mlcubes","title":"Running MLCubes","text":"<p>Docker runner runs the following command:   <pre><code>${docker.docker} run {run_args} ${docker.env_args} {volumes} ${docker.image} {task_args}\n</code></pre> where:</p> <ul> <li><code>${docker.docker}</code> is the docker executable.</li> <li><code>{run_args}</code> are either <code>${docker.cpu_args}</code> or <code>${docker.gpu_args}</code> depending on <code>${platform.num_accelerators}</code> value.</li> <li><code>${docker.env_args}</code> are the docker environmental variables.</li> <li><code>{volumes}</code> are the mount points that the runner automatically constructs based upon the task input/output   specifications.  </li> <li><code>${docker.image}</code> is the docker image name.  </li> <li><code>{task_args}</code> is the task command line arguments, constructed automatically by the runner.  </li> </ul>"},{"location":"runners/gcp-runner/","title":"Google Compute Platform (GCP) Runner","text":"<p>Attention</p> <p>MLCube\u00ae is under active development. Allocating and using instances in clouds are associated with costs. Users of    GCP runners should be aware about it, especially, taking into account capability of GCP runners to automatically    create and start remote instances. GCP RUNNERS in current implementation DO NOT stop/destroy remote instances.    Users are encouraged to visit web consoles to identify what virtual instances exist and run.</p> <p>Warning</p> <p>GCP runner can update users' <code>${HOME}/.ssh/config</code> configuration files.</p> <p>GCP runner is a frontend runner for running MLCubes in Google cloud. It is called a frontend runner because it does not actually run cubes, but ensures that a remote instance is up and running, and then uses other runners to actually run MLCubes. The following chain of runners is supported and has been tested:</p> <ol> <li>A user interacts with GCP runners. These runners are responsible for creating remote instances (if they do not     exist), start them, install required software stack (such as docker or singularity).</li> <li>Once a remote instance is up and running, GCP runners delegates further execution to other runners, such as     SSH runners. SSH runners are responsible for delivering    MLCubes to remote instances. SSH runners then delegate the actual execution of cubes on those remote instances to    such runners as docker runner or     singularity runner.</li> </ol> <p>The described scenario assumes the presence of the following platform configuration files: GCP, SSH and one of Docker or Singularity. As MLCube project evolves, other paths may become possible to run cubes in clouds such as GCP.</p>"},{"location":"runners/gcp-runner/#pre-requisites","title":"Pre-requisites","text":"<p>To use GCP runners, users need to have a GCP account. The following account details must be known and available in advance:</p> <ol> <li>Project ID.</li> <li>Zone.</li> <li>Service account JSON file.</li> <li>Users should configure their GCP accounts so that ever new virtual instance is automatically deployed with user     public key making it available through SSH access automatically.</li> </ol>"},{"location":"runners/gcp-runner/#creating-remote-instances","title":"Creating remote instances","text":"<p>Remote instances for running MLCubes can be created manually or automatically. </p> <ol> <li>To create a virtual instance manually, go to GCP console, select <code>Compute Engine</code> and then <code>VM instances</code>. Write    down an instance name.</li> <li>To create a virtual instance automatically, a GCP platform file needs be configured. A limited functionality is    supported. Basically, users can only specify <code>machine type</code> and <code>disk size</code>. Ubuntu 18.04 OS will be used as a base    image.</li> </ol>"},{"location":"runners/gcp-runner/#configuration-parameters","title":"Configuration parameters","text":"<pre><code>gcp:\n  # These are your project ID and zone names. \n  project_id: ''\n  zone: ''\n  # As described above, ensure you have service account activated and download your JSON key file.\n  credentials:\n    file: '${HOME}/.gcp/service_account_key_file.json'\n    scopes: ['https://www.googleapis.com/auth/cloud-platform']\n# Instance parameters.\n#    If existing remote instance is used, only `name` field is used. Other fields are not taken \n#    into account. If users want GCP runners to automatically create remote instances, all three \n#    fields must present. Instance name is arbitrary name for this instance. Machine type must be\n#    the valid GCP machine type. Ubuntu 18.04 is used as a base OS. \ninstance:\n  name: ''\n  machine_type: ''\n  disk_size_gb: ''\n# As described above, primary role of GCP runners is to ensure a remote instance exists before \n# delegating the actual `MLCube run` functionality to other runners. Currently, the only available \n# option is an SSH runner (that assumes remote instances are available vis SSH i.e. they have \n# public IPs). The `platform` field below specifies what runner the GCP runner should be using\n# once GCP virtual instance has been created. An SSH runner needs to be configured separately \n# (see sections below for some recommendations and best practices). \nplatform: ''\n</code></pre>"},{"location":"runners/gcp-runner/#configuring-mlcubes","title":"Configuring MLCubes","text":"<p>GCP runners execute the following steps during the configuration phase:</p> <ol> <li>Check that SSH access has been configured. A runner loads users <code>${HOME}/.ssh/config</code> file and verifies it      contains a section for the remote instance there (specified by the name). The configuration section must define      <code>User</code> and <code>IdentityFile</code>.</li> <li>GCP runner connects to GCP using provided project ID, zone name and <code>credentials</code> (file name and scopes).</li> <li>GCP runner checks if a remote instance exists with the provided name. If it does not exist, it creates it using three    parameters described above - instance name, machine type and disk size.</li> <li>If a remote instance is not running, GCP runner starts it.</li> <li>GCP runner retrieves a remote instance's metadata that includes public IP address. If public IP address does not     match <code>HostName</code> in ssh configuration file, GCP RUNNER UPDATES USER SSH CONFIG FILE.</li> <li>Currently, GCP runner automatically installs such packages, as <code>docker</code>, <code>python3</code> and <code>virtualenv</code>.</li> <li>GCP runner calls SSH runner to continue configuring remote instance in a MLCube-specific way.</li> </ol>"},{"location":"runners/gcp-runner/#running-mlcubes","title":"Running MLCubes","text":"<p>GCP runner does not implement any specific logic and redirects its functionality to an SSH runner.   </p>"},{"location":"runners/gcp-runner/#recommendations","title":"Recommendations","text":"<ol> <li>One remote instance can be used to run different MLCubes. Names of remote instances can reflect their type, for    instance, <code>gcp_free_micro_instance</code>, <code>gcp_4_cpu_instance</code>, <code>gcp_1_gpu_instance</code>, <code>gcp_8_gpu_instance</code> etc.</li> <li>Following the above guidelines, these instances must be configured with key-based SSH access (GCP and SSH runners    depend on this). Each remote instance must have a section in the <code>{HOME}/.ssh/config</code> that should look like:    <pre><code>Host mlcube-gcp-instance-n1s4\n    HostName {{PUBLIC_IP_ADDRESS}}\n    IdentityFile ~/.ssh/gcp_rsa\n    User {{GCP_USER_LOGIN_NAME}}\n</code></pre>    GCP runner will update the <code>HostName</code> value if actual IP address differs from existing one. Other fields are never    updated by GCP runners. Section like this one is sufficient to partially configure GCP and fully configure SSH    runners.</li> <li>After every GCP run, decide if a remote instance needs to be stopped/destroyed. If so, go to web console.  </li> </ol>"},{"location":"runners/kubeflow/","title":"Kubeflow Runner","text":"<p>Warning</p> <p>MLCube\u00ae Kubeflow runner is work in progress. Some functionality described below may not be available.</p> <p>Kubeflow supports two mandatory commands - <code>configure</code> and <code>run</code> with standard arguments - <code>mlcube</code>, <code>platform</code> and  <code>task</code>. Users can configure SSH runner in system setting file, and override parameters on a command line.</p> <p>Attention</p> <p>The <code>configure</code> command is not required, and does nothing when invoked.</p>"},{"location":"runners/kubeflow/#configuration-parameters","title":"Configuration parameters","text":"<pre><code># Use image name from docker configuration section\nimage: ${docker.image}\n# PVC must point to the active MLCube workspace now.\npvc: '???'\n# eg: set http://127.0.0.1:8000/pipeline when port forwarded svc/ml-pipeline-ui to port 8000\npipeline_host: ''\n</code></pre>"},{"location":"runners/kubeflow/#configuring-mlcubes","title":"Configuring MLCubes","text":"<p>This runner does not need configure step.</p>"},{"location":"runners/kubeflow/#running-mlcubes","title":"Running MLCubes","text":"<p>To be done.</p>"},{"location":"runners/kubernetes/","title":"Kubernetes Runner","text":"<p>Warning</p> <p>Work in progress. Some functionality described below may not be available.</p> <p>The Kubernetes Runner runs a MLCube\u00ae on a Kubernetes cluster.</p>"},{"location":"runners/kubernetes/#why-kubernetes","title":"Why Kubernetes?","text":"<p>One of the key goals of the MLCube project is to enable portability of ML models. Kubernetes offers a good set of  abstractions to enable model training to be portable across different compute platforms.</p>"},{"location":"runners/kubernetes/#design","title":"Design","text":"<p>Kubernetes Runner Proposal Doc</p> <p>The Kubernetes runner takes in a kubernetes specific task file in the <code>run</code> directory and re-uses the Docker runner platform config and prepares a Kubernetes Job manifest. The runner then creates the job on the Kubernetes cluster.</p> <p></p>"},{"location":"runners/kubernetes/#configuration-parameters","title":"Configuration parameters","text":"<p>Attention</p> <p>Currently, users must create persistent volume claim (PVC) that points to an actual MLCube workspace directory.</p> <pre><code># By default, PVC name equals to the name of this MLCube (mnist, matmul, ...).\npvc: ${name}\n# Use image name from docker configuration section.\nimage: ${docker.image}\n</code></pre> <p>The Kubernetes runner constructs the following Kubernetes Job manifest. </p> <pre><code>apiVersion: batch/v1\nkind: Job\nmetadata:\n  namespace: default\n  generateName: mlcube-mnist-\nspec:\n  template:\n    spec:\n      containers:\n      - name: mlcube-container\n        image: mlcommons/mlcube:mnist\n        args:\n        - --data_dir=/mnt/mlcube/mlcube-input/workspace/data\n        - --model_dir=/mnt/mlcube/mlcube-output/workspace/model\n        volumeMounts:\n        - name: mlcube-input\n          mountPath: /mnt/mlcube/mlcube-input\n        - name: mlcube-output\n          mountPath: /mnt/mlcube/mlcube-output\n      volumes:\n      - name: mlcube-input\n        persistentVolumeClaim:\n          claimName: mlcube-input\n      - name: mlcube-output\n        persistentVolumeClaim:\n          claimName: mlcube-output\n      restartPolicy: Never\n  backoffLimit: 4\n</code></pre>"},{"location":"runners/kubernetes/#configuring-mlcubes","title":"Configuring MLCubes","text":"<p>This runner does not need configure step.</p>"},{"location":"runners/kubernetes/#running-mlcubes","title":"Running MLCubes","text":"<p>Algorithm is following:</p> <ul> <li>Load Kubernetes configuration.</li> <li>Create job manifest (see above).</li> <li>Create job and wait for completion.</li> </ul>"},{"location":"runners/singularity-runner/","title":"Singularity Runner","text":"<p>Singularity runner uses singularity to run MLCube\u00ae cubes. It supports two mandatory commands - <code>configure</code> and <code>run</code> with standard arguments - <code>mlcube</code>, <code>platform</code> and <code>task</code>. Users can configure Singularity runner in MLCube  configuration file, system setting file, and override parameters on a command line.</p>"},{"location":"runners/singularity-runner/#configuration-parameters","title":"Configuration parameters","text":"<p>MLCube reference singularity runner supports the following configuration parameters (with default values): <pre><code># Name of a singularity image, for instance \"mnist-0.0.1.simg\".\nimage: ${singularity.image}\n# Path where to build the image. By default, it is `.image` inside workspace directory.\nimage_dir: ${runtime.workspace}/.image\n\n# Singularity executable\nsingularity: singularity\n\n# Build arguments\nbuild_args: --fakeroot\n# Singularity recipe file relative to workspace.\nbuild_file: Singularity.recipe\n</code></pre></p>"},{"location":"runners/singularity-runner/#configuring-mlcubes","title":"Configuring MLCubes","text":"<p>Users do not need to run the <code>configure</code> command manually, singularity docker runs this whenever image is not found.  Singularity runner under the hood runs the following command line: <pre><code>cd {recipe_path} &amp;&amp; ${singularity} build ${build_args} {image_uri} ${build_file}\n</code></pre> where:  </p> <ul> <li><code>{recipe_path}</code> is the MLCube root directory.</li> <li><code>${singularity}</code> is the singularity executable.</li> <li><code>${build_args}</code> is the singularity build arguments.</li> <li><code>{image_uri}</code> is the full image path (<code>${image_dir}/${image}</code>).  </li> <li><code>${build_file}</code> is the singularity build file. </li> </ul>"},{"location":"runners/singularity-runner/#running-mlcubes","title":"Running MLCubes","text":"<p>Singularity runner runs the following command:   <pre><code>${singularity} run {volumes} {image_path} {task_args}\n</code></pre> where:   </p> <ul> <li><code>${singularity}</code> is the singularity executable.</li> <li><code>{volumes}</code> are the mount points that the runner automatically constructs based upon the task input/output   specifications.  </li> <li><code>{image_path}</code> is the path to Singularity image (<code>{image_dir}/{image}</code>).  </li> <li><code>{task_args}</code> is the task command line arguments, constructed automatically by the runner.  </li> </ul>"},{"location":"runners/ssh-runner/","title":"SSH Runner","text":"<p>Warning</p> <p>Work in progress. Some functionality described below may not be available.</p> <p>SSH runner uses other runners to run MLCube\u00ae cubes on remote hosts. It uses <code>ssh</code> and <code>rsync</code> internally. It supports two mandatory commands - <code>configure</code> and <code>run</code> with standard arguments - <code>mlcube</code>, <code>platform</code> and <code>task</code>. Users  can configure SSH runner in system setting file, and override parameters on a command line.</p>"},{"location":"runners/ssh-runner/#configuration-parameters","title":"Configuration parameters","text":"<pre><code># Remote host name or IP address\nhost: ''\n# Platform (runner) to use on remote host\nplatform: ''\n# Root path for MLCubes on remote host\nremote_root: ''\n# Remote python interpreter. It's a dictionary. \n# - Must contain:\n#   - `type`: interpreter type (system, virtualenv)\n# - When type is system (system-wide interpreter), additional parameters must be:\n#   - `python`: python executable, maybe full path or just `python`.\n#   - `requirements`: is a whitespace-separated list of python dependencies.\n# - When type is virtualenv (python environment created with virtualenv tool), \n#   additional parameters must be:\n#   - `python`: python executable\n#   - `requirements`: is a whitespace-separated list of python dependencies.\n#   - `location`: path where virtual environment must be created.\n#   - `name`: name of the virtual environment.\ninterpreter: {}          \n# Authentication on remote host. It's a dictionary that contain the following fields:\n#   - `identify_file`: if present, will be used as part of the connection \n#     string ('-i {identity_file}')\n#   - `user`: username for the remote host, will be used as '{user}@{host}'\nauthentication: {}\n</code></pre> <p>SSH runner uses IP or name of a remote host (<code>host</code>) and ssh tool to log in and execute shell commands on remote hosts.  If passwordless login is not configured, SSH runner asks for password many times during configure and run phases.  </p>"},{"location":"runners/ssh-runner/#configuring-mlcubes","title":"Configuring MLCubes","text":"<p>Attention</p> <p>This runner must be configured by users explicitly: <code>mlcube configure --mlcube=. --platform=ssh</code></p> <p>During the <code>configure</code> phase, the following steps are performed.</p> <ul> <li>Based upon configuration, SSH runner creates and/or configures python on a remote host using <code>ssh</code>. This includes   execution of such commands as <code>virtualenv -p ...</code> and/or <code>source ... &amp;&amp; pip install ...</code> on a remote host.</li> <li>SSH runner copies mlcube directory to a remote host.</li> <li>SSH runner runs another runner specified in a platform configuration file on a remote host to configure it. </li> </ul>"},{"location":"runners/ssh-runner/#running-mlcubes","title":"Running MLCubes","text":"<p>During the run phase, the SSH runner performs the following steps:</p> <ul> <li>It uses <code>ssh</code> to run standard <code>run</code> command on a remote host.  </li> <li>It uses <code>rsync</code> to synchronize back the content of the <code>{MLCUBE_ROOT}/workspace</code> directory.   </li> </ul>"},{"location":"tutorials/create-mlcube/","title":"Tutorial: Create an MLCube","text":"<p>Interested in getting started with MLCube\u00ae? Follow the instructions in this tutorial.    </p>"},{"location":"tutorials/create-mlcube/#step-1-setup","title":"Step 1: Setup","text":"<p>Get MLCube, MLCube examples and MLCube Templates, and CREATE a Python environment. <pre><code># You can clone the mlcube examples and templates from GtiHub\ngit clone https://github.com/mlcommons/mlcube_examples\n\n# Create a python environment\nvirtualenv -p python3 ./env &amp;&amp; source ./env/bin/activate\n\n# Install mlcube, mlcube-docker and cookiecutter \npip install mlcube mlcube-docker cookiecutter \n</code></pre></p>"},{"location":"tutorials/create-mlcube/#step-2-configure-mlcube-using-the-mlcube_cookiecutter","title":"Step 2: Configure MLCube using the mlcube_cookiecutter","text":"<p>Let's use the <code>matmul</code> example, that we downloaded in the previous step, to illustrate how to make an MLCube. Matmul  is a simple matrix multiply example written in Python with TensorFlow. When you create an MLCube for your own model  you will use your own code, data and dockerfile.</p> <pre><code># make the mlcube examples root directory your current directory\ncd mlcube_examples\n\n# rename matmul reference implementation from matmul to matmul_reference\nmv ./matmul ./matmul_reference\n\n# create a mlcube directory using mlcube template(note: do not use quotes\n# in your input to cookiecutter): \n#    mlcube_name = matmul\n#    mlcube_description = Matrix multiplication example\n#    author_name = MLPerf Best Practices Working Group\n#    author_email =  first.second@corp.com\n#    author_org = corp\ncookiecutter https://github.com/mlcommons/mlcube_cookiecutter.git\n\n# copy the matmul.py,Dockerfile and requirements.txt to your \n# mlcube_matmul/build directory\ncp matmul_reference/matmul.py matmul/\ncp matmul_reference/Dockerfile matmul/\ncp matmul_reference/requirements.txt matmul/\n\n# copy input file for matmul to workspace directory\ncp -R  matmul_reference/workspace matmul\n</code></pre> <p>Edit the template files Start by looking at the mlcube.yaml file that has been generated by cookiecutter.  <pre><code>cd ./matmul\n</code></pre></p> <p>Cookiecutter has modified the lines shown in bold in the mlcube.yaml file shown here:</p> <pre><code> \n# This YAML file marks a directory to be an MLCube directory. When running MLCubes with runners, \n# MLCube path is specified using `--mlcube` runner command line argument. The most important \n# parameters that are defined here are (1) name, (2) author and (3) list of MLCube tasks.\n\n# MLCube name (string). Replace it with your MLCube name (e.g. \"MNIST\").\nname: matmul\n\n# MLCube description (string). Replace it with your MLCube name\n# (e.g. \"MLCommons MNIST MLCube example\").\ndescription: Matrix multiplication example\n\n# List of authors. Cookiecutter sets the first author.\nauthors:\n  - name: MLPerf Best Practices Working Group\n    email: first.second@corp.com\n    org: corp\n\n# This dictionary can contain information about SW/HW requirements\nplatform: {}\n#  accelerator_count: 0\n#  accelerator_maker: NVIDIA\n#  accelerator_model: A100-80GB\n#  host_memory_gb: 40\n#  need_internet_access: True\n#  host_disk_space_gb: 100\n\n# This cookiecutter creates a docker-based MLCube.\ndocker:\n  image: mlcommons/matmul:0.0.1\n\n# List of MLCube tasks supported by this MLCube.\ntasks:\n  matmul:\n    parameters:\n      inputs: {parameters_file: parameters_file.yaml}\n      outputs: {output_file: {type: file, default: output.txt}}\n</code></pre> <p>Our input file shapes.yaml that we have copied previously into the mlcube workspace contains input parameters to  set matrix dimensions. We need to remove the automatically generated parameters file. <pre><code>rm workspace/parameters_file.yaml\n</code></pre></p> <p>Now we will edit file mlcube.yaml. The lines you need to edit are shown in bold shown here:  </p> <pre><code>\n# This YAML file marks a directory to be an MLCube directory. When running MLCubes with runners, \n# MLCube path is specified using `--mlcube` runner command line argument. The most important \n# parameters that are defined here are (1) name, (2) author and (3) list of MLCube tasks.\n\n# MLCube name (string). Replace it with your MLCube name (e.g. \"MNIST\").\nname: matmul\n\n# MLCube description (string). Replace it with your MLCube name \n# (e.g. \"MLCommons MNIST MLCube example\").\ndescription: Matrix multiplication example\n\n# List of authors. Cookiecutter sets the first author.\nauthors:\n  - name: MLPerf Best Practices Working Group\n    email: first.second@corp.com\n    org: corp\n\n# This dictionary can contain information about SW/HW requirements\nplatform: {}\n#  accelerator_count: 0\n#  accelerator_maker: NVIDIA\n#  accelerator_model: A100-80GB\n#  host_memory_gb: 40\n#  need_internet_access: True\n#  host_disk_space_gb: 100\n\n# This cookiecutter creates a docker-based MLCube.\ndocker:\n  image: mlcommons/matmul:v1.0\n\n# List of MLCube tasks supported by this MLCube.\ntasks:\n  matmul:\n    parameters:\n      inputs: {parameters_file: shapes.yaml}\n      outputs: {output_file: {type: file, default: matmul_output.txt}}\n</code></pre>"},{"location":"tutorials/create-mlcube/#step-3-build-docker-container-image","title":"Step 3: Build Docker container Image","text":"<pre><code>mlcube configure --mlcube=. --platform=docker -Prunner.build_strategy=auto\n</code></pre>"},{"location":"tutorials/create-mlcube/#step-4-test-your-mlcube","title":"Step 4: Test your MLCube","text":"<pre><code># Run `matmul` task\nmlcube run --mlcube=. --platform=docker --task=matmul\n\n# Show the content of the workspace directory \nls ./workspace\n\n# Show the content of the file generated by `matmul` task\ncat ./workspace/matmul_output.txt\n</code></pre>"}]}